{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff9e59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "def setup(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "\n",
    "    # initialize the process group\n",
    "    dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n",
    "\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()\n",
    "    \n",
    "world_size = 4\n",
    "rank = 4\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import wandb\n",
    "import random\n",
    "import pdb\n",
    "from tqdm import tqdm\n",
    "from torchray.attribution.grad_cam import grad_cam\n",
    "from torchvision import datasets, models, transforms\n",
    "from models import MyCustomResnet18, AdvisingNetwork\n",
    "from params import RunningParams\n",
    "from helpers import HelperFunctions\n",
    "\n",
    "from ffcv.loader import Loader, OrderOption\n",
    "from ffcv.fields.decoders import \\\n",
    "    RandomResizedCropRGBImageDecoder\n",
    "from ffcv.fields.basics import IntDecoder\n",
    "from ffcv.transforms import ToTensor, Convert, ToDevice, Squeeze, NormalizeImage, \\\n",
    "    RandomHorizontalFlip, ToTorchImage\n",
    "from ffcv.transforms import *\n",
    "import torchvision as tv\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4,5,6,7\"\n",
    "\n",
    "RunningParams = RunningParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcda58c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_name = 'resnet18'\n",
    "MODEL1 = models.resnet18(pretrained=True).eval().cuda()\n",
    "\n",
    "data_dir = '/home/giang/Downloads/advising_net_training/'\n",
    "virtual_train_dataset = '{}/train'.format(data_dir)\n",
    "\n",
    "train_dataset = '/home/giang/Downloads/datasets/random_train_dataset'\n",
    "val_dataset = '/home/giang/Downloads/datasets/imagenet1k-val'\n",
    "\n",
    "# if not HelperFunctions.is_running(os.path.basename(__file__)):\n",
    "if True:\n",
    "    print('Creating symlink datasets ...')\n",
    "    if os.path.islink(virtual_train_dataset) is True:\n",
    "        os.unlink(virtual_train_dataset)\n",
    "    os.symlink(train_dataset, virtual_train_dataset)\n",
    "\n",
    "    virtual_val_dataset = '{}/val'.format(data_dir)\n",
    "    if os.path.islink(virtual_val_dataset) is True:\n",
    "        os.unlink(virtual_val_dataset)\n",
    "    os.symlink(val_dataset, virtual_val_dataset)\n",
    "else:\n",
    "    print('Script is running! No creating symlink datasets!')\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          RunningParams.data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "pdist = nn.PairwiseDistance(p=2)\n",
    "\n",
    "\n",
    "\n",
    "IMAGENET_MEAN = np.array([0.485, 0.456, 0.406]) * 255\n",
    "IMAGENET_STD = np.array([0.229, 0.224, 0.225]) * 255\n",
    "DEFAULT_CROP_RATIO = 224/256\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83c8836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "\n",
    "            distributed = 1\n",
    "            order = OrderOption.RANDOM if distributed else OrderOption.QUASI_RANDOM\n",
    "            if RunningParams.FFCV_loader is True:\n",
    "                data_loader = Loader('ffcv_output/imagenet_{}.beton'.format(phase),\n",
    "                                     batch_size=RunningParams.batch_size,\n",
    "                                     num_workers=32,\n",
    "                                     order=order,\n",
    "                                     os_cache=True,\n",
    "                                     drop_last=True,\n",
    "                                     pipelines={'image': [\n",
    "                                      RandomResizedCropRGBImageDecoder((224, 224)),\n",
    "                                      RandomHorizontalFlip(),\n",
    "                                      ToTensor(),\n",
    "                                      ToDevice(torch.device('cuda:0'), non_blocking=True),\n",
    "                                      ToTorchImage(),\n",
    "                                      # Standard torchvision transforms still work!\n",
    "                                      NormalizeImage(IMAGENET_MEAN, IMAGENET_STD, np.float32)\n",
    "                                     ], 'label':\n",
    "                                     [\n",
    "                                        IntDecoder(),\n",
    "                                        ToTensor(),\n",
    "                                        Squeeze(),\n",
    "                                        ToDevice(torch.device('cuda:0'), non_blocking=True),\n",
    "                                            ]},\n",
    "                                     distributed=distributed\n",
    "                                     )\n",
    "            else:\n",
    "                data_loader = torch.utils.data.DataLoader(\n",
    "                    image_datasets[phase],\n",
    "                    batch_size=RunningParams.batch_size,\n",
    "                    shuffle=True,  # turn shuffle to True\n",
    "                    num_workers=8,\n",
    "                    pin_memory=True,\n",
    "                )\n",
    "\n",
    "            if phase == 'train':\n",
    "                model.train()  # Training mode\n",
    "            else:\n",
    "                model.eval()  # Evaluation mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            yes_cnt = 0\n",
    "            true_cnt = 0\n",
    "\n",
    "            for batch_idx, (data, gt) in enumerate(tqdm(data_loader)):\n",
    "                # x = data.cuda()\n",
    "                # gts = gt.cuda()\n",
    "                x = data # No moveing to cuda based on https://github.com/libffcv/ffcv/issues/179#issuecomment-1058222330\n",
    "                gts = gt\n",
    "\n",
    "                out = MODEL1(x)\n",
    "                model1_p = torch.nn.functional.softmax(out, dim=1)\n",
    "                score, index = torch.topk(model1_p, 1, dim=1)\n",
    "                predicted_ids = index.squeeze()\n",
    "\n",
    "                model2_gt = (predicted_ids == gts) * 1  # 0 and 1\n",
    "\n",
    "                # TODO: Incorporate confidence score: Correct = confidence score, Wrong = 1 confidence score\n",
    "                # for gt_idx in range(len(model2_gt)):\n",
    "                #     if model2_gt[gt_idx].item() == 1:\n",
    "                #         model2_gt[gt_idx] = [1 - score[gt_idx].detach().item(), score[gt_idx].detach().item()]\n",
    "                #     else:\n",
    "                #         model2_gt[gt_idx] = [score[gt_idx].detach().item(), 1 - score[gt_idx].detach().item()]\n",
    "\n",
    "                saliency = grad_cam(MODEL1, x, index, saliency_layer=RunningParams.GradCAM_RNlayer, resize=True)\n",
    "                explanation = torch.amax(saliency, dim=(1, 2, 3,))  # normalize the heatmaps\n",
    "                explanation = torch.div(saliency, explanation.reshape(data.shape[0], 1, 1, 1))  # scale to 0->1\n",
    "\n",
    "                # Incorporate explanations\n",
    "                if RunningParams.XAI_method == 'No-XAI':\n",
    "                    inputs = x\n",
    "                elif RunningParams.XAI_method == 'GradCAM':\n",
    "                    inputs = explanation * x  # multiply query & heatmap\n",
    "\n",
    "                labels = model2_gt\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    if RunningParams.advising_network is True:\n",
    "                        output = model(x, saliency, model1_p)\n",
    "                        p = torch.nn.functional.softmax(output, dim=1)\n",
    "                        _, preds = torch.max(p, 1)\n",
    "                        loss = criterion(p, labels)\n",
    "                        # why val loss is so slow? debug the p and preds here\n",
    "\n",
    "                    else:\n",
    "                        ds_output, fc_output = model(inputs)\n",
    "                        # print(fc_output[0][0])\n",
    "                        model2_p = torch.nn.functional.softmax(fc_output, dim=1)\n",
    "                        p = torch.nn.functional.softmax(ds_output, dim=1)\n",
    "                        _, preds = torch.max(p, 1)\n",
    "\n",
    "                        p2 = torch.nn.functional.softmax(fc_output, dim=1)\n",
    "                        score2, _ = torch.topk(p2, 1, dim=1)\n",
    "\n",
    "                        if RunningParams.top1 is True:\n",
    "                            confidence_loss = pdist(score.squeeze(), score2.squeeze())\n",
    "                        else:\n",
    "                            confidence_loss = pdist(model2_p, model1_p).mean()\n",
    "\n",
    "                        label_loss = criterion(p, labels)\n",
    "                        # If true --> penalize the old softmax -> 1 at the place, all other 0\n",
    "                        # If wrong --> penalize the top-1 -> 0 at the place, all other\n",
    "                        # TODO: add criterion to penalize the softmax score\n",
    "                        if RunningParams.confidence_loss is True:\n",
    "                            loss = 0.5 * confidence_loss + 0.5 * label_loss\n",
    "                        else:\n",
    "                            loss = label_loss\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                yes_cnt += sum(preds)\n",
    "                true_cnt += sum(labels)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / len(image_datasets[phase])\n",
    "            epoch_acc = running_corrects.double() / len(image_datasets[phase])\n",
    "            yes_ratio = yes_cnt.double() / len(image_datasets[phase])\n",
    "            true_ratio = true_cnt.double() / len(image_datasets[phase])\n",
    "\n",
    "            wandb.log({'{}_accuracy'.format(phase): epoch_acc, '{}_loss'.format(phase): epoch_loss})\n",
    "\n",
    "            print('{} - Loss: {:.4f} Acc: {:.2f} - Yes Ratio: {:.2f} - True Ratio: {:.2f}'.format(\n",
    "                phase, epoch_loss, epoch_acc*100, yes_ratio * 100, true_ratio*100))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "                ckpt_path = '/home/giang/Downloads/advising_net_training/best_models/best_model_{}.pt'\\\n",
    "                    .format(wandb.run.name)\n",
    "\n",
    "                torch.save({\n",
    "                    'epoch': epoch+1,\n",
    "                    'model_state_dict': best_model_wts,\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'val_loss': epoch_loss,\n",
    "                    'val_acc': epoch_acc*100,\n",
    "                }, ckpt_path)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7dfd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RunningParams.advising_network is True:\n",
    "    model2_name = 'AdvisingNetwork'\n",
    "    MODEL2 = AdvisingNetwork()\n",
    "else:\n",
    "    model2_name = 'MyCustomResnet18'\n",
    "    MODEL2 = MyCustomResnet18(pretrained=True, fine_tune=RunningParams.fine_tune)\n",
    "\n",
    "# MODEL2 = MODEL2.cuda()\n",
    "# MODEL2 = nn.DataParallel(MODEL2)\n",
    "\n",
    "\n",
    "setup(rank, world_size)\n",
    "\n",
    "MODEL2 = MODEL2.to(rank)\n",
    "MODEL2 = DDP(MODEL2, device_ids=[rank])\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(MODEL2.parameters(), lr=RunningParams.learning_rate, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "oneLR_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer_ft, max_lr=0.01,\n",
    "    steps_per_epoch=dataset_sizes['train']//RunningParams.batch_size,\n",
    "    epochs=RunningParams.epochs)\n",
    "\n",
    "config = {\"train\": train_dataset,\n",
    "          \"val\": val_dataset,\n",
    "          \"train_size\": dataset_sizes['train'],\n",
    "          \"val_size\": dataset_sizes['val'],\n",
    "          \"model1\": model1_name,\n",
    "          \"model2\": model2_name,\n",
    "          \"num_epochs\": RunningParams.epochs,\n",
    "          \"batch_size\": RunningParams.batch_size,\n",
    "          \"learning_rate\": RunningParams.learning_rate,\n",
    "          'explanation': RunningParams.XAI_method,\n",
    "          'confidence_loss': RunningParams.confidence_loss,\n",
    "          'top1': RunningParams.top1,\n",
    "          'fine_tuning': RunningParams.fine_tune,\n",
    "          'advising_net': RunningParams.advising_network,\n",
    "          'query_frozen': RunningParams.query_frozen,\n",
    "          'heatmap_frozen': RunningParams.heatmap_frozen,\n",
    "          }\n",
    "\n",
    "\n",
    "print(config)\n",
    "wandb.init(\n",
    "    project=\"advising-network\",\n",
    "    entity=\"luulinh90s\",\n",
    "    config=config\n",
    ")\n",
    "\n",
    "world_size = 4\n",
    "mp.spawn(fn=train_model, args=(MODEL2,\n",
    "    criterion,\n",
    "    optimizer_ft,\n",
    "    oneLR_scheduler,\n",
    "    config[\"num_epochs\"]), nprocs=world_size, join=True)\n",
    "\n",
    "# _, best_acc = train_model(\n",
    "#     MODEL2,\n",
    "#     criterion,\n",
    "#     optimizer_ft,\n",
    "#     oneLR_scheduler,\n",
    "#     config[\"num_epochs\"])\n",
    "wandb.finish()\n",
    "\n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbf333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import os\n",
    "\n",
    "def is_running(script):\n",
    "    for q in psutil.process_iter():\n",
    "        if q.name().startswith('python'):\n",
    "            if len(q.cmdline())>1 and script in q.cmdline()[1] and q.pid !=os.getpid():\n",
    "                print(\"'{}' Process is already running\".format(script))\n",
    "                return True\n",
    "\n",
    "    return False\n",
    "\n",
    "if not is_running(\"train.py\"):\n",
    "    n = input(\"What is Your Name? \")\n",
    "    print (\"Hello \" + n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c97c69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

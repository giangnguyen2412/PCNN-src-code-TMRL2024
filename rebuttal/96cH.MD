We sincerely thank the Reviewer for the feedback and constructive suggestions.
Please find our responses to each of your concerns below:

> (Weaknesses 1) When compared to other existing classifiers, the propsed method is slower than k-NN and prototypical part-based classifiers but quicker than CHM-Corr and EMD-Corr re-rankers. Although it is in line with existing methods, its slower speed could be a drawback in situations where efficiency is crucial.

> (Requested Changes 1) Include a discussion on potential strategies to address the challenge of extended inference time.

We would like to respond to both of these concerns together because they are closely related.

As the total runtime of our method is computed by: 

T = T_RN50 + T_kNN + T_S (Equation. 3 in paper) 

where T_RN50 is the time to do inference with pretrained classifier C (here RN50), T_kNN is the time to retrieve nearest neighbors, and T_S is the time to compute the similarity scores using S.
Below, we show that we can significantly reduce T_kNN and T_S while maintaining the accuracy of our method:

(1) Reducing T_kNN by shrinking training set during inference

We reduce the training set from 100% → 50% → 33% of the original size and observe the effect on the accuracy and runtime.
Here is the experimental data on CUB-200 and Dogs-120:

| Dataset   | % Data | Samples per Class | Top-1 Acc(%) | Runtime (s) |
|-----------|--------|-------------------|--------------|-------------|
| CUB-200   | 100%   | 30                | 88.43        | 64.55       |
| CUB-200   | 50%    | 15                | 88.26        | 59.70       |
| CUB-200   | 33%    | 10                | 88.19        | 58.08       |
| Dogs-120  | 100%   | 100               | 86.27        | 87.18       | 
| Dogs-120  | 50%    | 50                | 86.32        | 71.02       |
| Dogs-120  | 33%    | 33                | 86.42        | 65.52       |

**_The top-1 accuracy and runtime of CxS on CUB-200 and Dogs-120 for different sizes of training data during inference. Runtime was computed over 1000 samples, similar to the setup in Appendix E._**

When keeping the same accuracy, we can reduce the runtime by 10% on CUB-200 and 24.9% on Dogs-120 by reducing the training set to 33% of the original size.

(2) Reducing T_S by reducing the number of comparisons done by S 

We can reduce the number of queries to the image comparator S by ignoring less probable labels.
We run an experiment for CUB-200 where we instead of re-ranking the whole **top-10**, we only re-rank the classes that have a probability `>= 1%` assigned by the base classifier C.

We found that:
- The CxS model accuracy on CUB-200 drops very marginally by `only 0.08%` (from `88.59%` → `88.51%`).
- However, the number of queries to the image comparator S was reduced by approx. `4x` (from `10` to just about `2.5` queries/image).
This leads to a `2.5x` speedup in the overall runtime of the CxS system (from `64.55` seconds to `28.95` seconds per 1000 images), as shown in the following Table.

|               Model                |   Time (s)   | Top-1 Acc (%) |
|:----------------------------------:|:------------:|:-------------:|
|          RN50 xS (before)          | 64.55 ± 0.35 |     88.59     |
|          RN50 xS (after)           | 28.95 ± 0.11 |     88.51     |

**_The run-time of CxS on 1,000 queries on one Nvidia V100 GPU._**

Both of these strategies can now be seen in the Sec. E of the latest version of our submission. 

We also include a discussion on potential strategies to further speed up runtime in response to the Reviewer `g7wm` [here](https://openreview.net/forum?id=OcFjqiJ98b&noteId=XuB3bY6d9q).
In this, we suggest to leverage GPU to speed up the nearest neighbor retrieval algorithm and use built-in options from `faiss` library to speed up the similarity computation.

> (Requested Changes 2) Can you determine an optimal value for K by considering the unique characteristics of each query or input, in order to enhance the balance between accuracy and runtime efficiency?

Thank you for your suggestion! 

Predicting an optimal K for each input image is an interesting idea yet requires building a separate predictive model that can be useful for many tasks. 
We are not aware of an existing tool that can already do this and therefore leave this idea for future work.

Yet, we agree with your concern of long runtime (due to a large K) and are proposing to reduce the K from 10 down to around 2.5 per query by using only the top labels with confidence scores > 0.01 assigned by classifier C.
We found that we can significantly reduce the runtime of CxS from 64.55 secs to 28.95 secs (around 2.5x) with a marginal drop (0.08%) in accuracy.

> (Requested Changes 3) Is it possible to implement incremental learning techniques to update the comparator S over time with new data?

Yes! It is possible to update S as our framework takes in two separate models: C and S. 
We don’t see our framework to impose any specific constraints against continual learning.
With popular incremental learning techniques, such as replay [1], pseudo-rehearsal[2] , or regularization [3], we can increasingly improve S over time by adding more data.

[1] Continual learning with deep generative replay, NeurIPS 2017
[2] ICARL: Incremental classifier and representation learning, CVPR 2017
[3] Learning without Forgetting, ECCV 2016